{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Encuesta.ipynb",
      "provenance": [],
      "mount_file_id": "1-BhTogfnA-6iIAIazRu_GlnTYHEXjvFn",
      "authorship_tag": "ABX9TyOS96IwIVLAABSyKDVSLAkS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cristiandarioortegayubro/Moodle/blob/master/Encuesta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44qM9YrTusP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENlcxc8xn6SY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f9aa224f-3834-49f9-a7fc-d30718ac66a0"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('Encuesta.txt', 'https://github.com/cristiandarioortegayubro/Moodle/blob/master/Encuesta.txt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/cristiandarioortegayubro/Moodle/blob/master/Encuesta.txt\n",
            "   8192/Unknown - 0s 0us/step"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxbvlt_noIYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heI05ZKqoLRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "930dbb93-5549-4d70-f975-3d4944c33f44"
      },
      "source": [
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 240778 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60N_NRzPoYHF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "74e6f943-8d21-4101-957d-227ee8bdb169"
      },
      "source": [
        "print(text[:250])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "<!DOCTYPE html>\n",
            "<html lang=\"en\">\n",
            "  <head>\n",
            "    <meta charset=\"utf-8\">\n",
            "  <link rel=\"dns-prefetch\" href=\"https://github.githubassets.com\">\n",
            "  <link rel=\"dns-prefetch\" href=\"https://avatars0.githubusercontent.com\">\n",
            "  <link rel=\"dns-prefetch\" href=\"h\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA3rvecbowHq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b390a563-c5de-41c3-87ab-87d4014a3850"
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "print ('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "106 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj3-r1zgo2K7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNm9XhHjo8R1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "e7f0ebcc-4c14-4816-c6af-b7c9d6662251"
      },
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  '\\t':   0,\n",
            "  '\\n':   1,\n",
            "  '\\r':   2,\n",
            "  ' ' :   3,\n",
            "  '!' :   4,\n",
            "  '\"' :   5,\n",
            "  '#' :   6,\n",
            "  '%' :   7,\n",
            "  '&' :   8,\n",
            "  \"'\" :   9,\n",
            "  '(' :  10,\n",
            "  ')' :  11,\n",
            "  '+' :  12,\n",
            "  ',' :  13,\n",
            "  '-' :  14,\n",
            "  '.' :  15,\n",
            "  '/' :  16,\n",
            "  '0' :  17,\n",
            "  '1' :  18,\n",
            "  '2' :  19,\n",
            "  ...\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gswqPPHypFN8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "168ed97a-fb7b-4533-f2ff-4d9dca5a2c7a"
      },
      "source": [
        "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'\\n\\n\\n\\n\\n\\n<!DOCTY' ---- characters mapped to int ---- > [ 1  1  1  1  1  1 29  4 37 48 36 53 58]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x_CLaBXpNDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c4c3dfda-7732-49b4-fdef-7649d4b023a2"
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ns1hiS-pUaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "25a51428-e943-4bde-9ba0-ea5b21062371"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'\\n\\n\\n\\n\\n\\n<!DOCTYPE html>\\n<html lang=\"en\">\\n  <head>\\n    <meta charset=\"utf-8\">\\n  <link rel=\"dns-prefetch\"'\n",
            "' href=\"https://github.githubassets.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://avatars0.githubuser'\n",
            "'content.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://avatars1.githubusercontent.com\">\\n  <link rel=\"'\n",
            "'dns-prefetch\" href=\"https://avatars2.githubusercontent.com\">\\n  <link rel=\"dns-prefetch\" href=\"https:/'\n",
            "'/avatars3.githubusercontent.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://github-cloud.s3.amazonaws.'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QgZbMhspcG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFcUJ1IUpkQS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "60bd514c-12fd-4302-f2c6-b2c5705ef95f"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  '\\n\\n\\n\\n\\n\\n<!DOCTYPE html>\\n<html lang=\"en\">\\n  <head>\\n    <meta charset=\"utf-8\">\\n  <link rel=\"dns-prefetch'\n",
            "Target data: '\\n\\n\\n\\n\\n<!DOCTYPE html>\\n<html lang=\"en\">\\n  <head>\\n    <meta charset=\"utf-8\">\\n  <link rel=\"dns-prefetch\"'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EsBGn6ZpqYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "137db2a2-b676-4060-acd6-680d8b7b4303"
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 1 ('\\n')\n",
            "  expected output: 1 ('\\n')\n",
            "Step    1\n",
            "  input: 1 ('\\n')\n",
            "  expected output: 1 ('\\n')\n",
            "Step    2\n",
            "  input: 1 ('\\n')\n",
            "  expected output: 1 ('\\n')\n",
            "Step    3\n",
            "  input: 1 ('\\n')\n",
            "  expected output: 1 ('\\n')\n",
            "Step    4\n",
            "  input: 1 ('\\n')\n",
            "  expected output: 1 ('\\n')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge4R_L-Lp01x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5669e874-155f-4929-b086-8f10ccbf6e25"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-5KgjXOp3VR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJJ65DntqALN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYIcndyCqG-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Asjp--rxqLJl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df58787f-82d4-4d95-edad-0e9fa8c93023"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 106) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il4zSfQ4qS_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "742b43b3-4982-44be-c014-f98c3f889816"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           27136     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 106)           108650    \n",
            "=================================================================\n",
            "Total params: 4,074,090\n",
            "Trainable params: 4,074,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNOP4QGKqa1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of7yy3XEqgZw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "70838119-83c1-422c-a3e6-703bd566d275"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  8,  17,  57,  48,  71,  15,  85,  36,  64,  68,   8,  71,   6,\n",
              "        29, 105, 102,  28,  91,   8,  33,  95,  28,   3,  91,   5,  66,\n",
              "        83, 100,  47,   8,  17,  21,  95,   4,  63,  61,  45,  43,   2,\n",
              "         0,  20,  47,  73,  96,  99,   6,  28, 102,  11,  37,  88,  19,\n",
              "        31,  11,  78,  99,  34,   5,  38,   7,  64,  97,  33,  72, 103,\n",
              "         0,  85,  25,  54,  43,  25,  18,  92,   5,  29,  65, 100,  42,\n",
              "        91,  54,  85,  19,  17,  66,   1,  49,  44, 100,  80,  88,  85,\n",
              "        11,  90,  75,  97,  32,  33,  84,  44,  98])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J61n-g8KqmhD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2ca272d1-a771-4422-ba11-d5598e54a113"
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " '\"1\"></td>\\n        <td id=\"LC1\" class=\"blob-code blob-code-inner js-file-line\">ENCUESTA DE INCIDENTES'\n",
            "\n",
            "Next Char Predictions: \n",
            " '&0XOj.xCcg&j#<↵ó;·&@Í; ·\"evíN&04Í!b`LJ\\r\\t3NlÑé#;ó)D{2>)qéA\"E%cÚ@kú\\tx8UJ81¿\"<díI·Ux20e\\nPKís{x)°nÚ?@wKá'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4zabfCyqrSv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ebfe8938-8b72-47b9-94f8-da1189fe97ad"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 106)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.6635118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26GoacoRq1JN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXo0IDNFq5dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjQb7K7kq7_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiHdMZJ9rDHM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "669f8e2a-c404-45d2-9a04-24c484ea8918"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "37/37 [==============================] - 2s 54ms/step - loss: 3.8935\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 2.5650\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 1.8292\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 1.4611\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 2s 52ms/step - loss: 1.2631\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 1.1388\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 1.0386\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.9503\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 2s 54ms/step - loss: 0.8693\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 2s 53ms/step - loss: 0.8017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSkhWv49t6Ou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c3a78ad-1b0d-4f55-d1a8-960f8cc788d9"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_10'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLCGCXm7uACb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_5FUDytuE5a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "9b74f4a8-7fc7-4f7a-fb8c-d08860aba58e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 256)            27136     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 106)            108650    \n",
            "=================================================================\n",
            "Total params: 4,074,090\n",
            "Trainable params: 4,074,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QUdzL_BuNQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 1000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihGIGALquQa_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "74f19bf7-6f87-4e53-96a6-d5e102ba5e58"
      },
      "source": [
        "print(generate_text(model, start_string=u\"RESPUESTAS \"))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RESPUESTAS PINO\r</td>\n",
            "      </tr>\n",
            "      <tr>\n",
            "        <td id=\"L68\" class=\"blob-num js-line-number\" data-line-number=\"36\"></td>\n",
            "       <td id=\"L63\" class=\"blob-num js-line-number\" data-line-number=\"301\"></td>\n",
            "        <td id=\"LC407\" class=\"blob-code blob-code-inner js-file-line\">Moria Cole MoHienande Mirtuclas dividas intI_Labgutes robor\r</td>\n",
            "      </tr>\n",
            "      <tr>\n",
            "        <td id=\"L331\" class=\"blob-num js-line-number\" datajs=\"p.1119 fa  <td id=\"LC525\" class=\"blob-code blob-code-inner js=\"inne-nowmosto me por alanacoríHa\r</td>\n",
            "      </tr>\n",
            "      <tr>\n",
            "       <td id=\"L240\" class=\"blob-num js-line-number\" data-cine-number=\"503\"></td>\n",
            "        <td id=\"LC337\" class=\"blob-code blob-codo-inner js-file-line\">Loctra VioZtonder        crass=\"loss-link-starthint-grbor=\"f25\">La idehron tual do mo ía  <tr id=\"LC683\" class=\"blob-code blob-code-inner js-file-line\">Fonten APanaa ARIIO\r</td>\n",
            "      </tr>\n",
            "    id=\"L412\" class=\"blob-num js-line-number\" data-line-number\" data-line-number=\"204\"></td>\n",
            "        <td id=\"LC529\" \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVOFGuo5ukbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWM3aTKduovP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aATJeRb4utmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, target):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inp)\n",
        "    loss = tf.reduce_mean(\n",
        "        tf.keras.losses.sparse_categorical_crossentropy(\n",
        "            target, predictions, from_logits=True))\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVjR4wEWuvoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "94ef59c6-44b0-468d-ca39-b72b9c421353"
      },
      "source": [
        "# Training step\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  # initializing the hidden state at the start of every epoch\n",
        "  # initally hidden is None\n",
        "  hidden = model.reset_states()\n",
        "\n",
        "  for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "    loss = train_step(inp, target)\n",
        "\n",
        "    if batch_n % 100 == 0:\n",
        "      template = 'Epoch {} Batch {} Loss {}'\n",
        "      print(template.format(epoch+1, batch_n, loss))\n",
        "\n",
        "  # saving (checkpoint) the model every 5 epochs\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "  print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
        "  print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.662336349487305\n",
            "Epoch 1 Loss 2.9775\n",
            "Time taken for 1 epoch 3.233853340148926 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.9274654388427734\n",
            "Epoch 2 Loss 2.1120\n",
            "Time taken for 1 epoch 2.0463290214538574 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 2.0432708263397217\n",
            "Epoch 3 Loss 1.7399\n",
            "Time taken for 1 epoch 2.046013116836548 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.3982681035995483\n",
            "Epoch 4 Loss 1.2447\n",
            "Time taken for 1 epoch 2.0631589889526367 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.3187611103057861\n",
            "Epoch 5 Loss 1.3256\n",
            "Time taken for 1 epoch 2.0916378498077393 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.1925995349884033\n",
            "Epoch 6 Loss 1.0149\n",
            "Time taken for 1 epoch 2.0815439224243164 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.9020484685897827\n",
            "Epoch 7 Loss 0.9475\n",
            "Time taken for 1 epoch 2.0868258476257324 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.8899851441383362\n",
            "Epoch 8 Loss 0.9093\n",
            "Time taken for 1 epoch 2.0864126682281494 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.7943480014801025\n",
            "Epoch 9 Loss 0.8178\n",
            "Time taken for 1 epoch 2.0856878757476807 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.7405799031257629\n",
            "Epoch 10 Loss 0.6490\n",
            "Time taken for 1 epoch 2.108705759048462 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}